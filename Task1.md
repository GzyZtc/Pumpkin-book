<h1>第一章 绪论</h1>
<h2>基本术语</h2>
<strong>数据集</strong><br>
数据集是一组数据的集合，这些数据可能具有相似性质或相同的来源。在机器学习和人工智能中，数据集通常用于训练模型或进行数据分析。<br>
数据集由若干个样本组成，每个样本由若干个特征组成，每个特征又对应一个属性值.<br>
例如，在鸢尾花分类问题中，数据集可能包括鸢尾花的萼片长度、宽度、花瓣长度和宽度等特征的数据以及每朵鸢尾花的类别（例如山鸢尾、变色鸢尾和维吉尼亚鸢尾）。<br>
总的来说，数据集是机器学习和人工智能领域中非常重要的一部分，因为模型的质量取决于训练数据的质量。<br>
<strong>属性，特征</strong><br>
在机器学习中，属性和特征都是指描述一个数据样本的信息。<br>
属性：是指一个数据样本具有的可测量的属性。比如在一个房屋价格预测的任务中，房子的面积、卧室数量、地理位置等都是房屋的属性。<br>
特征：是指一个数据样本的描述性信息。在机器学习中，特征是用来描述样本的信息，以便于模型学习样本和标签之间的关系。特征可以是属性，也可以是属性的组合或者变换。<br>
实际上，属性和特征是可以互换使用的，在数据预处理和特征工程这一步骤中，我们可能会将属性变换成特征，也可能会将特征变换成属性。<br>
一般来说，属性指的是原始数据中的可测量值，而特征指的是数据预处理过程中提取出来的描述数据的信息。<br>
<strong>属性值</strong><br>
属性值是表中每一行特定列的值，它可以是数字，文本，日期，布尔值或其他数据类型。<br>
比如一张员工表<br>

| Employee    | Firts Name  |last Name|Salary |
| ----------- | ----------- |---------|-------|
| 1           | John        |Smith    |$50,000|
| 2           | Jane        |Doe      |$60,000|
<br>
在这个表中，属性包括 Employee ID, First Name, Last Name, 和 Salary，属性值分别是1, John, Smith, $50,000。<br>
属性值是每行每列的值，例如第一行第一列的属性值是1，第二行第二列的属性值是Jane等。
<br>
<strong>属性空间</strong><br>
在数学中，属性空间是一组可能出现在属性上的所有可能值的集合。 在数据库系统和机器学习中，属性空间也被称为特征空间。<br>
例如，在上面的员工表的例子中，属性 "Employee ID" 的属性空间是整数的集合，属性 "Salary" 的属性空间是实数的集合，属性 "First Name" 和 "Last Name" 的属性空间是字符串的集合。<br>
在机器学习中，属性空间是用来表示输入数据的空间，在这里模型会学习特征和标签之间的关系<br>
<strong>输入空间</strong><br>
输入空间：是模型可以接受的输入数据的集合。在机器学习中，输入空间是指模型可以接受的输入数据的集合。 比如一个线性回归模型可能需要向量值作为输入空间。<br>
<strong>样本空间</strong>
样本空间是指所有可能的样本的集合。在机器学习中，样本空间包含了所有可能的输入样本，这些样本被用来训练模型或进行数据分析。<br>
样本空间的大小取决于样本的特征数量和取值范围。如果样本具有高维特征，那么样本空间将会很大。如果样本具有限制的取值范围，那么样本空间将会相对较小。<br>
在机器学习算法中，通常使用一个训练集来构建模型，训练集是样本空间的一个子集。这个训练集被用来学习模型的参数，并且模型在样本空间中进行预测或分类.<br>

>属性空间，样本空间和输入空间都是数学概念，但它们在具体应用中有细微的差别
在上面的员工表的例子中：<br>
属性空间：<br>
属性 "Employee ID" 的属性空间是整数的集合<br>
属性 "Salary" 的属性空间是实数的集合<br>
属性 "First Name" 和 "Last Name" 的属性空间是字符串的集合<br>
样本空间：<br>
样本空间是所有可能的员工记录的集合。<br>
输入空间：<br>
如果我们将这个表中的每一行视为一个输入样本，那么输入空间就是所有这样的样本，每个样本都是由4个属性组成的，并且每个属性都只能取属性空间中的值。<br>
总结来说，属性空间是指某种特征可能取的所有值的集合，样本空间是所有可能的样本的集合，输入空间是模型可以接受的输入数据的集合。<br>

总之，样本空间是机器学习算法中重要的概念，它提供了所有可能的样本，用来训练模型和进行预测.<br>
<strong>特征向量</strong><br>
样本空间中的特征向量指的是描述每个样本的数值型信息，通常用来表示样本的特征。<br>
在机器学习中，特征向量是一组数值，它们描述了样本中每个特征的取值。每个特征对应一维，所有特征构成了特征向量。这些特征向量被用来表示样本，并且是机器学习算法中的基本元素。<br>
例如，在鸢尾花分类问题中，每朵鸢尾花可能由四个特征组成：萼片长度、宽度、花瓣长度和宽度。对于每朵鸢尾花，可以创建一个四维特征向量来表示这些特征。<br>
总之，特征向量是机器学习算法中的重要组成部分，它们提供了关于样本的重要信息，帮助模型进行预测和分类。<br>
<h2>假设空间</h2>
在机器学习中，假设空间（hypothesis space）是指所有可能的假设（hypothesis）的集合。假设是指一个模型或函数，用来描述样本和样本标签之间的关系。假设空间包含了所有可能的假设，其中一些假设可能更好地描述样本，而其他假设可能不能。<br>
假设空间的大小取决于假设的复杂度和数量。如果假设空间包含了大量简单的假设，则假设空间将会很大。如果假设空间包含了少量复杂的假设，则假设空间将会相对较小。<br>
<br>

>这里我们的假设空间由形如"(色泽=?)$\wedge$(根蒂=?)$\wedge$(敲声=?)"的可能取值
所形成的假设组成.例如色泽有"青绿""乌黑""浅白"这三种可能取值;还需考虑到，也许"色泽"无论取什么值都合适，我们用通配符"\*"来表示，例如"好瓜件(色泽=*)$\wedge$(根蒂口蜷缩)$\wedge$(敲声=浊响)"，即"好瓜是根蒂蜷缩、敲声浊响的瓜，什么色泽都行"此外，还需考虑极端情况:有可能"好
瓜"这个概念根本就不成立，世界上没有"好瓜"这种东西;我们用m表示这个假设.这样，若"色泽""根蒂""敲声"分别有3、2、2种可能取值，则我们面临的假设空间规模大小为4X3X3+1=37

<br>
在机器学习算法中，经常使用贪心算法或搜索算法来从假设空间中找到最优假设。这样的算法通常被称为假设空间搜索算法。<br>
总之，假设空间是机器学习中重要的概念，它包含了所有可能的假设，并且用于找到最优假设，从而描述样本和样本标签之间的关系。<br>
<strong>归纳学习</strong><br>
归纳学习（inductive learning）是一种机器学习方法，它指的是从一些样本数据中推断出一般规律的过程。这种方法中，算法从一些已知样本中学习规律，然后将其应用到未知样本上。<br>
归纳学习可以分为两类：<b>监督学习和无监督学习。</b><br>
监督学习是指算法从已知样本中学习，这些样本具有标签，表示它们的正确类别。监督学习的目的是找到一个函数，使用这个函数可以将未知样本正确分类。<br>
无监督学习是指算法从未标记样本中学习。它的目的是找到样本之间的关系或规律，而不是将样本分类。<br>
总的来说，归纳学习是机器学习的一个重要方法，它通过对已知样本的分析来预测未知样本。<br>

<h2>归纳偏好</h2>


<h1>第二章 模型的评估和选择</h1>
<h2>经验误差与过拟合</h2>
<h3>训练误差，泛化误差</h2>
在机器学习中，训练误差和泛化误差是用来评估模型性能的重要指标。<br>
训练误差：是指模型在训练数据集上的预测误差。训练误差可以通过度量模型在训练数据上的预测结果和真实结果之间的差距来计算。一般来说，训练误差越低说明模型在训练数据上的表现越好。<br>
泛化误差：是指模型在新数据上的预测误差，也就是模型在未知数据上的预测误差。泛化误差反映了模型的泛化能力，也就是模型对新数据的适用性。一般来说，泛化误差越低说明模型的泛化能力越强。<br>
在实际应用中，训练误差和泛化误差之间存在一个权衡关系，我们希望训练误差尽量低，但是过于低的训练误差可能会导致过拟合。过拟合就是模型过于复杂，对训练数据有很好的预测能力，但对新数据的预测能力差。所以，我们需要通过不断调整模型的复杂度来平衡训练误差和泛化误差。<br>
最终，我们需要在训练误差和泛化误差之间找到一个平衡点，让模型具有较高的预测能力和较好的泛化能力。这个平衡点可以通过不同的方法来获得，比如增加训练数据，减少模型复杂度，使用正则化等。<br>
总之，训练误差和泛化误差是衡量模型性能的重要指标，在机器学习中我们需要考虑如何在训练误差和泛化误差之间找到平衡点。<br>
<h3>过拟合，欠拟合</h3>
<b>过拟合</b>指的是模型在训练集上表现良好，但是在新的数据上的表现不佳。这种情况发生在模型太复杂，以至于它学习了训练数据中的“噪声”，而不是真正的规律。过拟合的解决方法包括使用更简单的模型，使用正则化，减少特征数量等<br>
<b>欠拟合</b>欠拟合指的是模型在训练集上表现不佳，也在新的数据上表现不佳。这种情况发生在模型不够复杂，无法学习训练数据中的真正规律。解决欠拟合的方法包括使用更复杂的模型，增加训练数据，增加特征数量等
<h2>评估方法</h2>
<h3>留出法</h3>
留出法(holdout method)是一种常用的模型评估方法，通常用于评估机器学习模型的泛化能力。
<br>
在留出法中，<b>我们将数据集分成两部分：训练集和测试集。我们使用训练集来训练模型，并使用测试集来评估模型的泛化能力</b>。通常，我们将数据集划分为训练集和测试集的比例在70%~80%训练集，20%~30%测试集左右。
<br>
与留出法相比，交叉验证法是另一种常用的模型评估方法，它可以更好地利用数据集中的所有样本来评估模型的泛化能力。
<h3>交叉验证法</h3>
交叉验证法(cross-validation)是一种常用的模型评估方法，通常用于评估机器学习模型的泛化能力。
<br>
在交叉验证法中，<b>我们将数据集分成若干个“折”（fold），每次选择一个“折”作为测试集，其余的“折”作为训练集</b>。在每次评估中，我们使用训练集来训练模型，并使用测试集来评估模型的性能。最后将每次评估得到的性能指标取平均值作为最终的性能指标。
<br>
常用的交叉验证方法有k-fold 交叉验证和留一法交叉验证。与留出法相比，交叉验证法更好地利用数据集中的所有样本来评估模型的泛化能力，使得模型评估结果更加准确。
<h3>自助法</h3>
自助法(Bootstrap)是一种常用的模型评估方法，通常用于估计模型的统计性质和不确定性。
<br>
自助法是通过<b>重复地从数据集中进行有放回采样</b>来估计统计性质和不确定性的。我们可以通过计算训练得到的模型在自助采样得到的数据集上的表现来估计模型的统计性质和不确定性。<br>

样本在m次采样中始终不被采到的概率$(1-\frac{1}{m})^{m},m\rightarrow \infty$为

$$\underset{m\rightarrow \infty}{\lim}(1-\frac{1}{m})^{m}\rightarrow\frac{1}{e}\approx 0.368$$

初始数据集D中约有36.8%的样本未出现在采样数据D'中，将D'用作训练集，将D\D'用作测试集
<br>
自助法具有较高的效率和灵活性，在数据集较小，难以划分训练/测试集时很有用常用于估计分类器的准确率和回归分析中的方差。

<h2>性能度量</h2>


在预测任务中，给定样例集$D=\{(x_{1},y_{1}),(x_2,y_2),...(x_m,y_m)\}$，其中$y_i$时示例$x_i$的真实标记，要评价学习器$f$的性能，就是要把学习器预测结果$f(x)$与真实标记$y$比较


<br>

回归任务最常用的性能度量是均方误差（MSE）<br>

$$E(f;D)=\frac{1}{m}\overset{m}{\underset{i=1}{\sum}}(f(x_i)-y_i)^2$$

更一般的，对于数据分布$\mathcal{D}$和概率密度函数$p(·)$,均方误差可描述为

<br>

$$E(f;D)=\int_{x\sim\mathcal{D}}(f(x)-y)^2p(x)dx$$

<h3>错误率与精度</h3>
对样例集D，分类错误率定义为<br>

$$E(f;D)=\frac{1}{m}\underset{i=1}{\overset{m}{\sum}\mathbb{I}}(f(x_i)\neq y_i)$$

精度则定义为<br>

$$acc(f;D)=\frac{1}{m}\overset{m}{\underset{i=1}{\sum}}\mathbb{II}(f(x_i)=y_i) \\=1-E(f;D) $$


更一般的
<h3>查准率，查全率与F1</h3>
<h3>ROC与AUC</h3>
<h3>代价敏感错误率与代价曲线</h4>
<h2>比较检验，假设检验</h2>
<h2>偏差与方差</h2>



